{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 words\n"
     ]
    }
   ],
   "source": [
    "# DICT_PATH = 'dicts/sortdict.txt.dict'\n",
    "DICT_PATH = 'dicts/test.txt.dict'\n",
    "words = open(DICT_PATH).read().split()\n",
    "print(len(words), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 nodes\n",
      "96 edges\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(G\u001b[38;5;241m.\u001b[39medges), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# from main import TELUGU_CONSONANTS, TELUGU_VOWELS, TELUGU_VOWEL_SIGNS, TELUGU_VIRAMA\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m pos \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mmultipartite_layout(G, subset_key\u001b[38;5;241m=\u001b[39mlayers)\n\u001b[1;32m     30\u001b[0m nt \u001b[38;5;241m=\u001b[39m Network()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/networkx/drawing/layout.py:1077\u001b[0m, in \u001b[0;36mmultipartite_layout\u001b[0;34m(G, subset_key, align, scale, center)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v, data \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1077\u001b[0m         layer \u001b[38;5;241m=\u001b[39m data[subset_key]\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   1079\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall nodes must have subset_key (default=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "import random\n",
    "words = random.sample(words, 10)\n",
    "\n",
    "layers = {}\n",
    "# add nodes\n",
    "for w in words:\n",
    "\tfor i in range(len(w)):\n",
    "\t\tG.add_node(w[i]+str(i), layer=i)\n",
    "\t\tif i not in layers:\n",
    "\t\t\tlayers[i] = []\n",
    "\t\tif w[i]+str(i) not in layers[i]:\n",
    "\t\t\tlayers[i].append(w[i]+str(i))\n",
    "# add edges\n",
    "for w in words:\n",
    "\tfor i in range(len(w)):\n",
    "\t\tfor j in range(i+1, len(w)):\n",
    "\t\t\tG.add_edge(w[i]+str(i), w[j]+str(j))\n",
    "\n",
    "print(len(G.nodes), 'nodes')\n",
    "print(len(G.edges), 'edges')\n",
    "\n",
    "# from main import TELUGU_CONSONANTS, TELUGU_VOWELS, TELUGU_VOWEL_SIGNS, TELUGU_VIRAMA\n",
    "pos = nx.multipartite_layout(G, subset_key=layers)\n",
    "\n",
    "nt = Network()\n",
    "\n",
    "for node in G.nodes:\n",
    "\tnt.add_node(node, label=node, x=pos[node][0]*500, y=pos[node][1]*500)\n",
    "\n",
    "for edge in G.edges:\n",
    "\tnt.add_edge(edge[0], edge[1])\n",
    "\t\n",
    "nt.from_nx(G)\n",
    "nt.show('nx.html', notebook=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
